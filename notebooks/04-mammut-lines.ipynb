{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c02ae76-b540-4b16-9492-e9210b3b9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICE'] = ''\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"text_recognizer\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccdb6dde-47e5-429a-88f2-0764fb7e259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cf50475-39f2-4642-a7d1-5bcbc0a036f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../training/conf/network/mammut_lines.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e52ecb01-c975-4e55-925d-1182c7aea473",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, \"rb\") as f:\n",
    "    cfg = OmegaConf.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f939aa37-7b1d-45cc-885c-323c4540bda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_target_': 'text_recognizer.network.mammut.MaMMUT', 'encoder': {'_target_': 'text_recognizer.network.vit.Vit', 'image_height': 56, 'image_width': 1024, 'patch_height': 56, 'patch_width': 8, 'dim': 512, 'encoder': {'_target_': 'text_recognizer.network.transformer.encoder.Encoder', 'dim': 512, 'heads': 12, 'dim_head': 64, 'ff_mult': 4, 'depth': 4, 'dropout_rate': 0.1}, 'channels': 1}, 'image_attn_pool': {'_target_': 'text_recognizer.network.transformer.attention.Attention', 'dim': 512, 'heads': 8, 'causal': False, 'dim_head': 64, 'ff_mult': 4, 'dropout_rate': 0.0, 'use_flash': True, 'norm_context': True, 'rotary_emb': None}, 'decoder': {'_target_': 'text_recognizer.network.transformer.decoder.Decoder', 'dim': 512, 'ff_mult': 4, 'heads': 12, 'dim_head': 64, 'depth': 6, 'dropout_rate': 0.1}, 'dim': 512, 'dim_latent': 512, 'num_tokens': 58, 'pad_index': 3, 'num_image_queries': 256}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aaeab329-aeb0-4a1b-aa35-5a2aab81b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = instantiate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "618b997c-e6a6-4487-b70c-9d260cb556d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7daf1f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "MaMMUT                                             [1, 89, 58]               627,712\n",
       "├─Vit: 1-1                                         [1, 128, 512]             --\n",
       "│    └─Sequential: 2-1                             [1, 128, 512]             --\n",
       "│    │    └─Rearrange: 3-1                         [1, 128, 448]             --\n",
       "│    │    └─LayerNorm: 3-2                         [1, 128, 448]             896\n",
       "│    │    └─Linear: 3-3                            [1, 128, 512]             229,888\n",
       "│    │    └─LayerNorm: 3-4                         [1, 128, 512]             1,024\n",
       "│    └─Encoder: 2-2                                [1, 128, 512]             --\n",
       "│    │    └─ModuleList: 3-5                        --                        --\n",
       "│    │    │    └─Attention: 4-1                    [1, 128, 512]             4,724,224\n",
       "│    │    │    └─Attention: 4-2                    [1, 128, 512]             4,724,224\n",
       "│    │    │    └─Attention: 4-3                    [1, 128, 512]             4,724,224\n",
       "│    │    │    └─Attention: 4-4                    [1, 128, 512]             4,724,224\n",
       "│    │    └─LayerNorm: 3-6                         [1, 128, 512]             1,024\n",
       "├─Attention: 1-2                                   [1, 257, 512]             --\n",
       "│    └─LayerNorm: 2-3                              [1, 257, 512]             1,024\n",
       "│    └─Linear: 2-4                                 [1, 257, 512]             262,144\n",
       "│    └─LayerNorm: 2-5                              [1, 128, 512]             1,024\n",
       "│    └─Linear: 2-6                                 [1, 128, 1024]            524,288\n",
       "│    └─Attend: 2-7                                 [1, 8, 257, 64]           --\n",
       "│    └─Linear: 2-8                                 [1, 257, 512]             262,144\n",
       "│    └─Sequential: 2-9                             [1, 257, 512]             --\n",
       "│    │    └─Linear: 3-7                            [1, 257, 4096]            2,101,248\n",
       "│    │    └─SwiGLU: 3-8                            [1, 257, 2048]            --\n",
       "│    │    └─Linear: 3-9                            [1, 257, 512]             1,049,088\n",
       "├─LayerNorm: 1-3                                   [1, 257, 512]             1,024\n",
       "├─Embedding: 1-4                                   [1, 89, 512]              29,696\n",
       "├─Decoder: 1-5                                     [1, 89, 512]              --\n",
       "│    └─ModuleList: 2-10                            --                        --\n",
       "│    │    └─ModuleList: 3-10                       --                        --\n",
       "│    │    │    └─Attention: 4-5                    [1, 89, 512]              4,724,224\n",
       "│    │    │    └─Attention: 4-6                    [1, 89, 512]              4,724,224\n",
       "│    │    └─ModuleList: 3-11                       --                        --\n",
       "│    │    │    └─Attention: 4-7                    [1, 89, 512]              4,724,224\n",
       "│    │    │    └─Attention: 4-8                    [1, 89, 512]              4,724,224\n",
       "│    │    └─ModuleList: 3-12                       --                        --\n",
       "│    │    │    └─Attention: 4-9                    [1, 89, 512]              4,724,224\n",
       "│    │    │    └─Attention: 4-10                   [1, 89, 512]              4,724,224\n",
       "│    │    └─ModuleList: 3-13                       --                        --\n",
       "│    │    │    └─Attention: 4-11                   [1, 89, 512]              4,724,224\n",
       "│    │    │    └─Attention: 4-12                   [1, 89, 512]              4,724,224\n",
       "│    │    └─ModuleList: 3-14                       --                        --\n",
       "│    │    │    └─Attention: 4-13                   [1, 89, 512]              4,724,224\n",
       "│    │    │    └─Attention: 4-14                   [1, 89, 512]              4,724,224\n",
       "│    │    └─ModuleList: 3-15                       --                        --\n",
       "│    │    │    └─Attention: 4-15                   [1, 89, 512]              4,724,224\n",
       "│    │    │    └─Attention: 4-16                   [1, 89, 512]              4,724,224\n",
       "│    └─LayerNorm: 2-11                             [1, 89, 512]              1,024\n",
       "├─Sequential: 1-6                                  [1, 89, 58]               --\n",
       "│    └─LayerNorm: 2-12                             [1, 89, 512]              1,024\n",
       "│    └─Linear: 2-13                                [1, 89, 58]               29,696\n",
       "====================================================================================================\n",
       "Total params: 80,711,552\n",
       "Trainable params: 80,711,552\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 80.08\n",
       "====================================================================================================\n",
       "Input size (MB): 0.23\n",
       "Forward/backward pass size (MB): 131.05\n",
       "Params size (MB): 320.34\n",
       "Estimated Total Size (MB): 451.61\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(net, ((1, 1, 56, 1024), (1, 89)), device=\"cpu\", depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "166bf656-aba6-4654-a530-dfce12666297",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = net(torch.randn(1, 1, 56, 1024), torch.randint(1, 4, (1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43d9af25-9872-497d-8796-4835a65262ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 58])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac7f1b-0eb1-4625-96b8-467846eb7ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
