{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"text_recognizer\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "\n",
    "from text_recognizer.networks.transformer.vit import ViT\n",
    "from text_recognizer.networks.transformer.transformer import Transformer\n",
    "from text_recognizer.networks.transformer.layers import Decoder\n",
    "from text_recognizer.networks.transformer.nystromer.nystromer import Nystromer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(dim=64, depth=2, num_heads=4, ff_kwargs={}, attn_kwargs={}, cross_attend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Attention(\n",
       "        (qkv_fn): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "          (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Residual()\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Attention(\n",
       "        (qkv_fn): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "          (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Residual()\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): FeedForward(\n",
       "        (mlp): Sequential(\n",
       "          (0): GEGLU(\n",
       "            (fc): Linear(in_features=64, out_features=512, bias=True)\n",
       "          )\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Residual()\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Attention(\n",
       "        (qkv_fn): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "          (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Residual()\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Attention(\n",
       "        (qkv_fn): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "          (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Residual()\n",
       "    )\n",
       "    (5): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): FeedForward(\n",
       "        (mlp): Sequential(\n",
       "          (0): GEGLU(\n",
       "            (fc): Linear(in_features=64, out_features=512, bias=True)\n",
       "          )\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Residual()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_decoder = Transformer(num_tokens=90, max_seq_len=690, attn_layers=decoder, emb_dim=64, emb_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (attn_layers): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Attention(\n",
       "          (qkv_fn): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "            (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "        )\n",
       "        (2): Residual()\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Attention(\n",
       "          (qkv_fn): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "            (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "        )\n",
       "        (2): Residual()\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): FeedForward(\n",
       "          (mlp): Sequential(\n",
       "            (0): GEGLU(\n",
       "              (fc): Linear(in_features=64, out_features=512, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Residual()\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Attention(\n",
       "          (qkv_fn): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "            (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "        )\n",
       "        (2): Residual()\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Attention(\n",
       "          (qkv_fn): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=12288, bias=False)\n",
       "            (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=4)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
       "        )\n",
       "        (2): Residual()\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): FeedForward(\n",
       "          (mlp): Sequential(\n",
       "            (0): GEGLU(\n",
       "              (fc): Linear(in_features=64, out_features=512, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Residual()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_emb): Embedding(90, 64)\n",
       "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (pos_emb): AbsolutePositionalEmbedding(\n",
       "    (emb): Embedding(690, 64)\n",
       "  )\n",
       "  (project_emb): Identity()\n",
       "  (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (logits): Linear(in_features=64, out_features=90, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_transformer = Nystromer(\n",
    "    dim = 64,\n",
    "    depth = 4,\n",
    "    num_heads = 8,\n",
    "    num_landmarks = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ViT(\n",
    "    dim = 64,\n",
    "    image_size = (576, 640),\n",
    "    patch_size = (64, 64),\n",
    "    transformer = efficient_transformer\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(4, 1, 576, 640).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = v(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = torch.randint(0, 90, (16, 690)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 90, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 690])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 690, 90])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_decoder(caption, context = o).shape # (1, 1024, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.networks.encoders.efficientnet import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = EfficientNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(en, (1, 576, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(efficient_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_transformer = efficient_transformer(num_landmarks=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../training/configs/vqvae.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.networks import VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VQVAE(**conf.network.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = torch.randn([2, 1, 576, 640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.encoder(datum)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae(datum)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = torch.randn([2, 1, 576, 640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg = torch.randint(0, 1000, [2, 682])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = torch.randn([2, 1, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../training/configs/cnn_transformer.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.networks.cnn_transformer import CNNTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CNNTransformer(input_shape=(1, 576, 640), output_shape=(682, 1), **conf.network.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.encode(datum).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t(datum, trg).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, n = 16, 128\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lambda: torch.ones((b, n), device=device).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones((b, n), device=device).bool().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 576, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "576 // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "640 // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 144, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size=16\n",
    "p = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
